{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBCyVYmb8OO7"
      },
      "source": [
        "!pip install git+https://github.com/aleju/imgaug"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qixUbenk8m3f"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import torchvision.datasets as D\n",
        "from imgaug import augmenters as iaa\n",
        "import imgaug as ia\n",
        "import numpy as np\n",
        "\n",
        "class MiRuido:\n",
        "  def __init__(self):\n",
        "    self.aug = iaa.SaltAndPepper(0.1)\n",
        "    \n",
        "  def __call__(self, img):\n",
        "    img = np.array(img)\n",
        "    return self.aug.augment_image(img)\n",
        "  \n",
        "\n",
        "dataset_train = D.FashionMNIST('./dataset', download=True, train=True, \n",
        "                               transform=T.ToTensor())\n",
        "dataset_test = D.FashionMNIST('./dataset', download=True, train=False,\n",
        "                              transform = T.ToTensor())\n",
        "\n",
        "dataset_train_x = D.FashionMNIST('./dataset', download=False, train=True,\n",
        "                                transform=T.Compose([MiRuido(),T.ToTensor()]))\n",
        "dataset_test_x = D.FashionMNIST('./dataset', download=False, train=False,\n",
        "                               transform=T.Compose([MiRuido(), T.ToTensor()]))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset_train, \n",
        "                                           batch_size=16, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset_test, \n",
        "                                           batch_size=16, shuffle=False)\n",
        "\n",
        "train_loader_x = torch.utils.data.DataLoader(dataset_train_x, \n",
        "                                           batch_size=16, shuffle=False)\n",
        "test_loader_x = torch.utils.data.DataLoader(dataset_test_x, \n",
        "                                           batch_size=16, shuffle=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btZLdyxn_hKu"
      },
      "source": [
        "#Inspeccion\n",
        "it1 = iter(train_loader)\n",
        "data1, target1 = next(it1)\n",
        "\n",
        "it2 = iter(train_loader_x)\n",
        "data2, target2 = next(it2)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "grid1 = torchvision.utils.make_grid(data1)\n",
        "plt.imshow(grid1.permute(1, 2, 0))\n",
        "plt.show()\n",
        "\n",
        "grid2 = torchvision.utils.make_grid(data2)\n",
        "plt.imshow(grid2.permute(1, 2, 0))\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFPtKbGAAW8N"
      },
      "source": [
        "class NoiseAutoencoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NoiseAutoencoder, self).__init__()\n",
        "    \n",
        "    self.encoder = nn.Sequential(nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
        "                                nn.ReLU(),\n",
        "                                nn.MaxPool2d(2,2),\n",
        "                                nn.Conv2d(16, 32, kernel_size = 3, padding=1),\n",
        "                                nn.ReLU(),\n",
        "                                nn.MaxPool2d(2, 2),\n",
        "                                nn.Conv2d(32, 16, kernel_size=3, padding=1),\n",
        "                                nn.ReLU(),\n",
        "                                nn.MaxPool2d(2, 2, padding=1))\n",
        "    self.decoder = nn.Sequential(nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Upsample(scale_factor=2),\n",
        "                                nn.Conv2d(16,32, kernel_size=3, padding=1),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Upsample(scale_factor=2),\n",
        "                                nn.Conv2d(32, 64, kernel_size=3),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Upsample(scale_factor=2),\n",
        "                                nn.Conv2d(64, 1, kernel_size=3, padding=1))\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return self.decoder(self.encoder(x))\n",
        "  \n",
        "\n",
        "net = NoiseAutoencoder()\n",
        "net = net.to('cuda')\n",
        "  \n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr = 0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENyU8PvbD81W"
      },
      "source": [
        "for epoch in range(10):\n",
        "  for x,y in zip(train_loader, train_loader_x):\n",
        "    x = x[0]\n",
        "    y = y[0]\n",
        "    \n",
        "    x = x.to('cuda')\n",
        "    y = y.to('cuda')\n",
        "    \n",
        "    output = net(y)\n",
        "    loss = criterion(output, x)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "  print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 10, loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Va-bESdFJee"
      },
      "source": [
        "data1,_ = next(iter(test_loader))\n",
        "data2,_ = next(iter(test_loader_x))\n",
        "\n",
        "with torch.no_grad():\n",
        "  out = net(data2.to('cuda'))\n",
        "  \n",
        "grid1 = torchvision.utils.make_grid(data1)\n",
        "plt.imshow(grid1.permute(1, 2, 0))\n",
        "plt.show()\n",
        "\n",
        "grid2 = torchvision.utils.make_grid(data2)\n",
        "plt.imshow(grid2.permute(1, 2, 0))\n",
        "plt.show()\n",
        "\n",
        "grid3 = torchvision.utils.make_grid(out.cpu())\n",
        "plt.imshow(grid3.permute(1, 2, 0))\n",
        "plt.show()\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mSTAsX0HNis"
      },
      "source": [
        "!wget http://www.ivan-sipiran.com/downloads/noisy_docs_data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaMG-U9WMB81"
      },
      "source": [
        "!unzip noisy_docs_data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfUrzHqDMdRH"
      },
      "source": [
        "import cv2\n",
        "\n",
        "img = cv2.imread('noisy_docs_data/train_cleaned/101.png')\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I2YWe_zNBRS"
      },
      "source": [
        "import PIL\n",
        "import glob\n",
        "\n",
        "class MiDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, root, tform=None, imgloader=PIL.Image.open):\n",
        "    super(MiDataset, self).__init__()\n",
        "    \n",
        "    self.root = root\n",
        "    self.filenames = sorted(glob.glob(root + '/*.png'))\n",
        "    self.tform = tform\n",
        "    self.imgloader = imgloader\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.filenames)\n",
        "  \n",
        "  def __getitem__(self, i):\n",
        "    out = self.imgloader(self.filenames[i])\n",
        "    if self.tform:\n",
        "      out = self.tform(out)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xohQ-od9Pizj"
      },
      "source": [
        "doc_train_dataset = MiDataset(root='noisy_docs_data/train',\n",
        "                             tform=T.Compose([T.Resize((258, 540)), \n",
        "                                              T.ToTensor()]))\n",
        "\n",
        "doc_train_loader = torch.utils.data.DataLoader(doc_train_dataset,\n",
        "                                               batch_size=4)\n",
        "\n",
        "doc_target_dataset = MiDataset(root='noisy_docs_data/train_cleaned',\n",
        "                             tform=T.Compose([T.Resize((258, 540)), \n",
        "                                              T.ToTensor()]))\n",
        "\n",
        "doc_target_loader = torch.utils.data.DataLoader(doc_target_dataset,\n",
        "                                               batch_size=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8I96WDYQdDm"
      },
      "source": [
        "class BackgroundRemoval(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(BackgroundRemoval, self).__init__()\n",
        "    \n",
        "    self.encoder = nn.Sequential(\n",
        "        nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2))\n",
        "    \n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Upsample(scale_factor=2),\n",
        "        nn.Conv2d(64, 1, kernel_size=3, padding=1))\n",
        "    \n",
        "  def forward(self,x):\n",
        "    return self.decoder(self.encoder(x))\n",
        "  \n",
        "net2 = BackgroundRemoval()\n",
        "net2 = net2.to('cuda')\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(net2.parameters(), lr=0.001)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spR1HN5iZnIg"
      },
      "source": [
        "for epoch in range(100):\n",
        "  for x,y in zip(doc_train_loader, doc_target_loader):\n",
        "    x = x.to('cuda')\n",
        "    y = y.to('cuda')\n",
        "    \n",
        "    output = net2(x)\n",
        "    loss = criterion(output, y)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "  print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 10, loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quiXSgW_Z6qk"
      },
      "source": [
        "doc_test_dataset = MiDataset(root='noisy_docs_data/test',\n",
        "                             tform=T.Compose([T.Resize((258, 540)), \n",
        "                                              T.ToTensor()]))\n",
        "\n",
        "doc_test_loader = torch.utils.data.DataLoader(doc_test_dataset,\n",
        "                                               batch_size=4)\n",
        "\n",
        "data3 = next(iter(doc_test_loader))\n",
        "grid3 = torchvision.utils.make_grid(data3, nrow=1)\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.imshow(grid3.permute(1, 2, 0))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3i5ykpzccbh"
      },
      "source": [
        "with torch.no_grad():\n",
        "  out = net2(data3.to('cuda'))\n",
        "  \n",
        "grid4 = torchvision.utils.make_grid(out.cpu(), nrow=1)\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.imshow(grid4.permute(1, 2, 0))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}